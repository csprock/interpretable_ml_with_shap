{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /app\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import ValidationCurveDisplay\n",
    "\n",
    "import shap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"/app/data/final.csv\", index_col=[0], parse_dates=True)\n",
    "data_df = data_df.dropna(subset=['wti_cush_spot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_var = \"wti_cush_spot\"\n",
    "x_var = [c for c in data_df.columns if c != y_var]\n",
    "\n",
    "validation_df = data_df.iloc[-52:]\n",
    "y_valid, X_valid = validation_df[y_var], validation_df[x_var]\n",
    "train_df = data_df.iloc[:-52]\n",
    "y_train, X_train = data_df[y_var], data_df[x_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train)\n",
    "# print the contents of the array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_param_grid = {\n",
    "    'n_estimators': np.arange(100, 1100, step=100),\n",
    "    'criterion': ['squared_error'],\n",
    "    'max_depth': 2**np.arange(0, 4, step=1),\n",
    "    'min_samples_split': 2**np.arange(1, 4, step=1),\n",
    "    'max_features': ['sqrt', 'log2', 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "model_rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "grid_search_cv = GridSearchCV(\n",
    "    estimator = model_rf,\n",
    "    param_grid=random_forest_param_grid,\n",
    "    cv = tscv,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    refit=True,\n",
    "    error_score='raise'\n",
    ")\n",
    "\n",
    "cv_results = grid_search_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_df = pd.DataFrame(grid_search_cv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cv_results(param_name):\n",
    "    best_params = grid_search_cv.best_params_\n",
    "    \n",
    "    # Create a list of parameters to filter by, excluding the specified parameter\n",
    "    filter_params = {param: value for param, value in best_params.items() if param != param_name}\n",
    "    \n",
    "    # Filter the results to only include rows with the best parameters for all except the specified parameter\n",
    "    filtered_results = cv_results_df.copy()\n",
    "    for param, value in filter_params.items():\n",
    "        filtered_results = filtered_results[filtered_results[f'param_{param}'] == value]\n",
    "    \n",
    "    # Plot the mean test score as a function of the specified parameter\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(filtered_results[f'param_{param_name}'], -filtered_results['mean_test_score'], marker='o')\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel('Negative Mean Squared Error')\n",
    "    plt.title(f'Cross-Validation Score as a Function of {param_name}')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "plot_cv_results('max_depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Predict on the validation set using the best model\n",
    "y_pred = grid_search_cv.best_estimator_.predict(X_valid)\n",
    "\n",
    "# Compute the mean absolute error\n",
    "mae = mean_absolute_error(y_valid, y_pred)\n",
    "print(f\"Mean Absolute Error on the validation set: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Convert the predictions and actual values to binary classes based on the sign\n",
    "y_valid_sign = y_valid.apply(lambda x: 1 if x > 0 else 0)\n",
    "y_pred_sign = np.where(y_pred > 0, 1, 0)\n",
    "\n",
    "# Calculate the classification metrics\n",
    "accuracy = accuracy_score(y_valid_sign, y_pred_sign)\n",
    "precision = precision_score(y_valid_sign, y_pred_sign)\n",
    "recall = recall_score(y_valid_sign, y_pred_sign)\n",
    "f1 = f1_score(y_valid_sign, y_pred_sign)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(grid_search_cv.best_estimator_)\n",
    "shap_values = explainer(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[16, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_ho_m1 = X_valid['ho_m1'].corr(y_valid)\n",
    "correlation_rbob_m1 = X_valid['rbob_m1'].corr(y_valid)\n",
    "\n",
    "print(f\"Correlation coefficient between ho_m1 and y_valid: {correlation_ho_m1}\")\n",
    "print(f\"Correlation coefficient between rbob_m1 and y_valid: {correlation_rbob_m1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
