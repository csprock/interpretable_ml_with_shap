{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretable Machine Learning with SHAP Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shap\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "shap.initjs()\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "#selected_features = ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup']\n",
    "X, y = shap.datasets.california()\n",
    "\n",
    "# combined dataframe\n",
    "df = pd.DataFrame(X, columns=X.columns)\n",
    "df['price'] = y\n",
    "\n",
    "#X = X[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate a profile report\n",
    "\n",
    "# # Or use the minimal option which might have fewer widget dependencies\n",
    "# profile = ProfileReport(df, title=\"California Housing Dataset Profile\", minimal=False)\n",
    "# # Save the report to an HTML file\n",
    "# profile.to_file(\"california_housing_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Motivating Example: Linear Regression\n",
    "\n",
    "Linear regression models are simply enough to be considered \"intrinsically interpretable\". The prediction from a linear model is simply the sum of the products of model coefficients and the variable values. \n",
    "\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_k x_k\n",
    "$$\n",
    "\n",
    "It might be tempting to use the magnitudes of the coefficients to determine the most important variables, but this would provide a misleading understanding of the model if the units of measure of the variables are different. \n",
    "\n",
    "In the California housing dataset, median income is measured in tens of thousands of dollars and the coefficient is 0.54, which is a similar magnitude to the rest of the coefficients. However, if we measure median income in dollars, then coefficient would 5 orders of magnitude greater than the rest of the coefficients and would be deemed the \"most important\" by magnitude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a linear regression model using the specified features\n",
    "linear_model_features = ['MedInc', 'HouseAge', 'AveRooms', 'AveOccup', 'Population', 'AveBedrms']\n",
    "X_train_selected = X_train[linear_model_features]\n",
    "X_test_selected = X_test[linear_model_features]\n",
    "\n",
    "# Initialize and train the linear regression model\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Print the model coefficients\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': linear_model_features,\n",
    "    'Coefficient': linear_model.coef_\n",
    "})\n",
    "print(\"Linear Regression Coefficients:\")\n",
    "print(coefficients)\n",
    "print(f\"\\nIntercept: {linear_model.intercept_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a way to view the importance of each variable for an *individual prediction*. Since the predicted value of a linear model is a linear sum of coefficients multipled by the value of the variable (the $\\beta_i  x_i$ terms in the sum), we can decompose the predictions into these products and view their magnitudes since they are all in the same unit of measure as the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate predictions manually by multiplying features by coefficients and adding intercept\n",
    "manual_predictions = np.dot(X_test_selected, linear_model.coef_) + linear_model.intercept_\n",
    "np.allclose(manual_predictions, linear_model.predict(X_test_selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a matrix of the products\n",
    "linear_components = pd.DataFrame(np.concatenate(\n",
    "    [\n",
    "        np.repeat(linear_model.intercept_, X_test_selected.shape[0]).reshape((-1, 1)), \n",
    "        np.multiply(X_test_selected.values, linear_model.coef_)\n",
    "    ], \n",
    "axis = 1), \n",
    "    columns = ['Intercept'] + linear_model_features\n",
    ")\n",
    "\n",
    "np.allclose(linear_components.sum(axis=1), (manual_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use these products as feature importances to create some simple visualizations such as a waterfall plot that shows how to get from the intercept of the model to the predicted value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_linear_prediction_waterfall\n",
    "plot_linear_prediction_waterfall(3, linear_components=linear_components,model=linear_model, X_test_selected=X_test_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Explainability for Tree-Based Models\n",
    "\n",
    "We just saw how linear models are easily interpreted and how you can get a nice, clean, preduction \n",
    "\n",
    "In modern applications, the best results are often obtained using large datasets and complex, non-linear models whose output is difficult to interpret and whose inner mechanics are non-transparent and difficult to understand. In many settings, tree-based methods such as random forests and gradient boosting machines achieve the best performance, especially on tabular data that is often found in the business world. \n",
    "\n",
    "(insert shap citation) identify three desirable properties that a good feature importance measure should have\n",
    "\n",
    "1. Consistency: If the model changes in such a way as to increase the marginal importance of a feature, the feature importance for that feature should not decrease\n",
    "2. Prediction-level explainations: the feature importance measure can explain individual predictions, not just the global importance for the entire model\n",
    "3. Local Accuracy (Additivity): the sum of the feature importance measures for an individual prediction sum to the predicted value, i.e. $f(x) = \\sum_{i} \\phi_i$ where the $\\phi_i$ are the feature importance measures for the $i$ th feature. (Note that this requires prediction-level explainations)\n",
    "\n",
    "\n",
    "There are numerous feature importance measures for use with both trees and other classes of models. The ones that are the most often used are:\n",
    "\n",
    "1. Permutation Importance \n",
    "2. Gain\n",
    "\n",
    "We will give an example of each and explain why none of these satisfy all three properties and then introduce SHAP as the only feature importance measure that satisfied all three. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Set up hyperparameter search for Random Forest Regressor\n",
    "# Define the parameter grid to search\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [None, 10, 20, 30, 40],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Create the random forest regressor\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Set up k-fold cross-validation\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Create the RandomizedSearchCV\n",
    "rf_random = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,  # Number of parameter settings to try\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=cv,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit the random search\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(\"Best Parameters:\", rf_random.best_params_)\n",
    "print(\"Best CV Score:\", -rf_random.best_score_)  # Convert back to positive MSE\n",
    "\n",
    "# Evaluate on test set\n",
    "best_rf = rf_random.best_estimator_\n",
    "test_score = best_rf.score(X_test, y_test)\n",
    "print(f\"R² Score on Test Set: {test_score:.4f}\")\n",
    "\n",
    "# Calculate MSE on test set\n",
    "y_pred = best_rf.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"MSE on Test Set: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation Importance\n",
    "\n",
    "Permutation importance works by randomly shuffing a feature then watching how accuracy of the model degrades. By breaking the dependence between the feature and the target variable, the idea is that we can see how much the model truely relies on that feature.\n",
    "\n",
    "Since permutation importances is measured with respect to model performance, computing it using the training set can provide misleading results on overfitted models, so it is best practice to calculate it using data not used to train the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Calculate permutation importance for RandomForest model\n",
    "\n",
    "# Calculate permutation importance\n",
    "perm_importance = permutation_importance(best_rf, X_test, y_test, n_repeats=50, random_state=42)\n",
    "\n",
    "# Sort the permutation importance by value\n",
    "sorted_indices = perm_importance.importances_mean.argsort()\n",
    "sorted_importances = perm_importance.importances_mean[sorted_indices]\n",
    "sorted_features = X.columns[sorted_indices]\n",
    "sorted_std = perm_importance.importances_std[sorted_indices]\n",
    "\n",
    "# Create horizontal bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(sorted_features)), sorted_importances, xerr=sorted_std, \n",
    "         color='skyblue', edgecolor='navy', alpha=0.7)\n",
    "\n",
    "# Add feature names as y-tick labels\n",
    "plt.yticks(range(len(sorted_features)), sorted_features)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Permutation Importance (Mean Decrease in Model Performance)')\n",
    "plt.title('Feature Importance based on Permutation Importance')\n",
    "\n",
    "# Add grid for better readability\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "\n",
    "# Adjust layout and display\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the actual values for reference\n",
    "for feature, importance, std in zip(sorted_features, sorted_importances, sorted_std):\n",
    "    print(f\"{feature}: {importance:.4f} ± {std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages\n",
    "\n",
    "* Easy to understand and implement; provides a quick, global overview of feature importance\n",
    "* Can be used with any model\n",
    "* Satisfies the *consistency* property\n",
    "\n",
    "### Disadvantages\n",
    "\n",
    "* Permuting the values of a single features can produce data points outside the distribution of the data when features are correlated. \n",
    "* Does not provide prediction-level feature importances and so cannot be locally accurate\n",
    "* Permutation importance can split the importance between correlated features, making one (or both) features seem less important than they actually are\n",
    "* Permutation importance uses the model *performance* instead of *output*, and this may not be what you want depending on the context\n",
    "\n",
    "The plot below uses some dummy data to illustrate the effect on the data disbritution of permuting a feature when two features are correlated. The points in red are the result of permuting Feature 1, which generates unrealistic data points that are outside the joint distribution of Features 1 and 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n_samples = 1000\n",
    "x1 = np.random.normal(0, 1, n_samples)\n",
    "x2 = 0.8 * x1 + 0.2 * np.random.normal(0, 1, n_samples)\n",
    "\n",
    "df_sample = pd.DataFrame({'feature1': x1, 'feature2': x2})\n",
    "\n",
    "X_permuted = df_sample.copy()\n",
    "\n",
    "# Select a slice from the middle of feature1's range to permute\n",
    "lower_bound = np.percentile(df_sample['feature1'], 25)\n",
    "upper_bound = np.percentile(df_sample['feature1'], 75)\n",
    "mask = (X_permuted['feature1'] >= lower_bound) & (X_permuted['feature1'] <= upper_bound)\n",
    "indices_to_permute = X_permuted[mask].index\n",
    "\n",
    "# Save original values for visualization\n",
    "original_values = X_permuted.loc[indices_to_permute, 'feature1'].copy()\n",
    "\n",
    "# Permute feature1 values within the selected range\n",
    "X_permuted.loc[indices_to_permute, 'feature1'] = np.random.permutation(original_values)\n",
    "\n",
    "# Calculate correlation\n",
    "original_corr = df_sample['feature1'].corr(df_sample['feature2'])\n",
    "permuted_corr = X_permuted['feature1'].corr(X_permuted['feature2'])\n",
    "\n",
    "# Create scatter plot to visualize the effect of permutation\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Plot all points in the original data\n",
    "plt.scatter(df_sample['feature1'], df_sample['feature2'], \n",
    "            alpha=0.5, label='Original Points', color='blue')\n",
    "\n",
    "# Highlight the permuted points\n",
    "plt.scatter(X_permuted.loc[indices_to_permute, 'feature1'], \n",
    "            X_permuted.loc[indices_to_permute, 'feature2'], \n",
    "            alpha=0.7, label='Permuted Points', color='red')\n",
    "\n",
    "# Add reference lines for the slice boundaries\n",
    "plt.axvline(x=lower_bound, color='gray', linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=upper_bound, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Demonstration of Permutation Method Issues with Correlated Features\\n'\n",
    "          f'Original Correlation: {original_corr:.3f}, After Permutation: {permuted_corr:.3f}')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Add annotation explaining the problem\n",
    "plt.annotate(\n",
    "    \"Permutation creates\\npoints outside the\\njoint distribution\",\n",
    "    xy=(-0.5, 1.5), xytext=(0.5, 2.0),\n",
    "    arrowprops=dict(facecolor='black', shrink=0.05, width=1.5, headwidth=8),\n",
    "    fontsize=12,\n",
    "    bbox=dict(boxstyle=\"round,pad=0.5\", fc=\"yellow\", alpha=0.8)\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gain \n",
    "\n",
    "Gain a feature importance measure that is unique to tree-based models that is calculated as the total reduction of loss or impurity contributed by all splits\n",
    "for a given feature. \n",
    "\n",
    "### Advantages\n",
    "\n",
    "* Is calculated \"for free\" with the training of the model\n",
    "\n",
    "\n",
    "### Disadvantages\n",
    "\n",
    "* Since it is based on the *training data*, it is suseptible to overfitting\n",
    "* Does not satisfy any of the three properties of consistency, prediction-level explainations or local accuracy\n",
    "* It favors continues features over categorical features since there are more opprotunities for splitting. This is also true for high-cardinality categorical features as well that have large numbers of possible splits to choose from\n",
    "* Not model agnostic, only works with tree-based methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate gain importance from the random forest model\n",
    "gain_importance = pd.Series(best_rf.feature_importances_, index=X_train.columns).sort_values(ascending=True)\n",
    "\n",
    "# Create horizontal bar plot for gain importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "gain_importance.plot.barh(color='salmon', edgecolor='darkred')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Gain Importance')\n",
    "plt.title('Feature Importance based on Gain (Gini Impurity Reduction)')\n",
    "\n",
    "# Add grid for better readability\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the actual values\n",
    "for feature, importance in gain_importance.items():\n",
    "    print(f\"{feature}: {importance:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to SHAP Values for Tree-Based Models\n",
    "\n",
    "SHAP values stand for **SHapley Additive Predictions** were introduced in 2017 by Lundberg and Lee [1]. They are based on Shapely values from cooperative game theory, which is a theoretically sound way to fairly allocate the payouts to players in a coopoerative game. We won't take the game theory connections too far here, but you can think of the \"game\" as the machine learning model being explained, the \"players\" as the input features to the model, and the \"payout\" the model predictions. SHAP values calculate the contribution each feature made to the prediction. \n",
    "\n",
    "Lundberg and Lee showed that SHAP values are the only explainatory model that satisfies the three properties that we discussed earlier. \n",
    "\n",
    "1. Consistency\n",
    "2. Local Accuracy / Additivity\n",
    "3. Prediction-level explainations\n",
    "\n",
    "Formally, additivity means that if $\\phi_i$ is the SHAP value for the $i$ feature, the sum of the SHAP values equals *the difference between the model output and the expected output*. \n",
    "\n",
    "$$\n",
    "f(x) = E[f(x)] + \\sum_{i=1}^F \\phi_i\n",
    "$$\n",
    "\n",
    "These properties unlock a variety of rich visualizations and diagnostic plots that we can use in place of the global feature importance measures that we just discussed. They can also be augmented by traditional Partial Dependence Plots and Individual Conditional Expectation plots, both of which we will review later in this presentation. \n",
    "\n",
    "### Some SHAP Theory\n",
    "\n",
    "Formally, let \n",
    "\n",
    "$$\n",
    "\\phi_i =  \\sum_{S\\subseteq F/\\{i\\}} \\frac{1}{|F|}  \\frac{1}{\\binom{|F|-1}{|S|}} \\big[ f_{S\\cup\\{i\\}} (x_{S\\cup\\{i\\}}) - f_S(x_S) \\big]\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "* $|F|$ is the number of features\n",
    "* $|S|$ is the number of features in the subset $S \\subset F$\n",
    "* $f_{S\\cup\\{i\\}}= E[f(x) | x_{S\\cup\\{i\\}}]$ is the conditional expectation of the model given the features $x_{S\\cup\\{i\\}}$\n",
    "* $ f_S = E[f(x) | x_S]$ is the conditional expectation of the model given the features $x_S$\n",
    "\n",
    "\n",
    "$\\phi_0 = f_\\empty(\\empty)$ \n",
    "\n",
    "**In Words**\n",
    "\n",
    "A one-line definition:\n",
    "\n",
    "> A SHAP value is the average marginal change in the model output from adding a feature to a subset of features, averaged over all such subsets not containing that feature. \n",
    "\n",
    "More precisely: \n",
    "\n",
    ">To calculate the SHAP value for feature $i$, we consider all possible subsets $S$ of features that exclude feature $i$. For each subset, we compute the marginal contribution of adding feature $i$ to that subset, which is the difference between the expected model output when $S$ and feature $i$ are known versus when only $S$ is known. We then take the weighted average of these contributions across all possible subsets where the weights are related to the number of such subsets. \n",
    "\n",
    "In steps: \n",
    "\n",
    "1. Train a machine learning model $f$\n",
    "2. For each feature $i$, consider all the subsets that exclude $i$\n",
    "3. Compute the expected difference in the expected model outputs $E[f(x) | x_{S\\cup\\{i\\}}] - E[f(x) | x_S]$ with and without the feature\n",
    "4. Average over all subsets, with weights equal to the probability of selecting that particular subset\n",
    "\n",
    "Let's unpack the last of these. The weights in the sum above are the probability of selecting a particular subset. The term has two parts: \n",
    "\n",
    "Given a feature $i$, the number of subsets of $S\\subseteq F / \\{i \\}$ is\n",
    "$$\n",
    "\\binom{|F|-1}{|S|}\n",
    "$$, \n",
    "\n",
    "so the probability of selecting a subset, conditional on $i$ (and assuming selection happens uniformly) is\n",
    "\n",
    "$$\n",
    " \\frac{1}{\\binom{|F|-1}{|S|}} \n",
    "$$\n",
    "\n",
    "Since there are $|F|$ features in the model, the probability of selecting one of them uniformly is $\\frac{1}{|F|}$. So the joint probability of selecting feature $i$ and subset $S\\subseteq F / \\{i \\}$ is therefore\n",
    "\n",
    "$$\n",
    "\\frac{1}{|F|}  \\frac{1}{\\binom{|F|-1}{|S|}} \n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import comb\n",
    "\n",
    "F = len(X.columns)\n",
    "\n",
    "combinations = {}\n",
    "for i in range(1, F):\n",
    "    combinations[i] = comb(F, i)\n",
    "\n",
    "# Create a DataFrame to store the combinations\n",
    "combinations_df = pd.DataFrame.from_dict(combinations, orient='index', columns=['Combinations'])\n",
    "combinations_df.reset_index(inplace=True)\n",
    "\n",
    "total_combinations = combinations_df['Combinations'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the number of combinations by subset size\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(combinations_df['index'], combinations_df['Combinations'], color='skyblue', edgecolor='navy')\n",
    "\n",
    "# Adding a curve to highlight the pattern\n",
    "plt.plot(combinations_df['index'], combinations_df['Combinations'], 'ro-', linewidth=2)\n",
    "\n",
    "# Add annotations for each point\n",
    "for i, row in combinations_df.iterrows():\n",
    "    plt.annotate(f\"{int(row['Combinations'])}\", \n",
    "                 (row['index'], row['Combinations']),\n",
    "                 textcoords=\"offset points\", \n",
    "                 xytext=(0,10), \n",
    "                 ha='center')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Size of Subset, |S|', fontsize=12)\n",
    "plt.ylabel('Number of Combinations', fontsize=12)\n",
    "plt.title(f'Number of Combinations for Subsets of |F| - 1 = 8 Features', fontsize=14)\n",
    "\n",
    "# Format x-axis\n",
    "plt.xticks(combinations_df['index'])\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add a note about the total\n",
    "plt.figtext(0.5, 0.01, f\"Total number of combinations: {total_combinations}\", \n",
    "            ha=\"center\", fontsize=12, bbox={\"facecolor\":\"lightgray\", \"alpha\":0.5, \"pad\":5})\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the number of possible combinations explodes exponentially with the number of features. The number of subsets in $F/\\{i\\}$ is 254, and since there are 9 features, the number of subsets to evaluate is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X.columns) * total_combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is a lot of subsets! As you can see, the number of subsets explodes exponentially with the number of features.\n",
    "\n",
    "\n",
    "### Computational Difficulties and TreeSHAP\n",
    "\n",
    "There are two main issues with SHAP values:\n",
    "\n",
    "1. Estimating the conditional expectations $E[f(x) | x_S]$ efficiently\n",
    "2. The combinatorical complexity of the SHAP value equation\n",
    "\n",
    "Fortunately, the breakthrough that Lundberg, Erion and Lee made in 2019 [2]  discovering a fast algorithm for computing SHAP values for tree-based models. The model is polynomial time, and allows large models with many features on large dataset to be explained quickly using SHAP. The algorithm is called TreeSHAP. \n",
    "\n",
    "The algorithm is able to compute  $E[f(x) | x_S]$ and does not require sampling or assuming features are independent (more on this later).\n",
    "\n",
    "# Visualizations and Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. Lundberg, S. M., & Lee, S.-I. (2017). *A Unified Approach to Interpreting Model Predictions*. In Proceedings of the 31st International Conference on Neural Information Processing Systems (NIPS 2017). [https://arxiv.org/abs/1705.07874](https://arxiv.org/abs/1705.07874)\n",
    "\n",
    "2. Lundberg, S. M., Erion, G. G., & Lee, S.-I. (2019). *Consistent Individualized Feature Attribution for Tree Ensembles*. arXiv preprint arXiv:1802.03888. [https://arxiv.org/abs/1802.03888](https://arxiv.org/abs/1802.03888)\n",
    "\n",
    "3. Frye, C., Rowat, C., & Feige, I. (2020). *Asymmetric Shapley Values: Incorporating Causal Knowledge into Model-Agnostic Explainability*. In Advances in Neural Information Processing Systems (NeurIPS 2020). https://arxiv.org/abs/1910.06358\n",
    "\n",
    "4. SHAP Documentation: https://shap.readthedocs.io\n",
    "\n",
    "5. Molnar, Christoph. *Interpretable Machine Learning: A Guide for Making Black Box Models Explainable*. 3rd ed., 2025. ISBN: 978-3-911578-03-5. Available at: https://christophm.github.io/interpretable-ml-book\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
